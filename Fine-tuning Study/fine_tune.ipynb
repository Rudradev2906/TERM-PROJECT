{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72146d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcb156e8b174d2db466b1a6200cc1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\datasets--imdb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6089abd5a346819f218db3fbfd9f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1640d9f307764f40a72e05a565de9f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccb30fbc9314e03995b981ce52e8758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914bcdee999545459ab48e88d79c2ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630219ff51064b0baa5ea79a044bb88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5118d862ad4d4c09bf0aad01450da756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def load_imdb_dataset():\n",
    "    imdb_dataset = load_dataset(\"imdb\")\n",
    "    N = 1000\n",
    "    rand_idx = np.random.randint(24999, size=N)\n",
    "    \n",
    "    x_train = imdb_dataset['train'][rand_idx]['text']\n",
    "    y_train = imdb_dataset['train'][rand_idx]['label']\n",
    "    \n",
    "    x_test = imdb_dataset['test'][rand_idx]['text']\n",
    "    y_test = imdb_dataset['test'][rand_idx]['label']\n",
    "    \n",
    "    return DatasetDict({'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n",
    "                        'test':Dataset.from_dict({'label':y_test,'text':x_test})})    \n",
    "\n",
    "dataset = load_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f5ca9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a48fd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.504)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b7064",
   "metadata": {},
   "source": [
    "## QLoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b79f7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.utils.quantization_config import BitsAndBytesConfig\n",
    "\n",
    "qlora_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44669e12",
   "metadata": {},
   "source": [
    "## Base Model : Pythia (2.8B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcde4bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa10ec4fc834271b8230eb477263ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--EleutherAI--pythia-2.8b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c240518b55d2436787f1bfa978186e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_1 = AutoModelForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/pythia-2.8b\",\n",
    "    num_labels = 2,\n",
    "    quantization_config = qlora_config,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c7b037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a87e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 2560)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (query_key_value): Linear4bit(in_features=2560, out_features=7680, bias=True)\n",
       "          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
       "          (dense_4h_to_h): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "  )\n",
       "  (embed_out): Linear(in_features=2560, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f0397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e21961f4bb45be89752d59ef5a21aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f40c7f64bcb41249d308e94235da10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99b48f951bd417b8b8ab42b1bf9fd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_1_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-2.8b\")\n",
    "\n",
    "if model_1_tokenizer.pad_token is None:\n",
    "    model_1_tokenizer.pad_token = model_1_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a740545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(model_1_tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c3a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Hi! How are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bbec244",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = model_1_tokenizer(test)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5feba774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12764, 2, 1359, 403, 368, 32]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1ab20",
   "metadata": {},
   "source": [
    "## LoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "247b7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e38008b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig\n",
    "\n",
    "model_1 = prepare_model_for_kbit_training(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff117eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config_model_1 = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93033a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = get_peft_model(model_1, lora_config_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd8ab0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,485,760 || all params: 2,785,694,720 || trainable%: 0.3764\n"
     ]
    }
   ],
   "source": [
    "model_1.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ffb5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = dataset['train']['text']\n",
    "train_labels = dataset['train']['label']\n",
    "test_texts = dataset['test']['text']\n",
    "test_labels = dataset['test']['label']\n",
    "\n",
    "import re\n",
    "\n",
    "for i in range(len(train_texts)):\n",
    "    train_texts[i] = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", train_texts[i])\n",
    "    train_texts[i] = re.sub(r\"\\s+\", \" \", train_texts[i]).strip()\n",
    "for i in range(len(test_texts)):\n",
    "    test_texts[i] = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", test_texts[i])\n",
    "    test_texts[i] = re.sub(r\"\\s+\", \" \", test_texts[i]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed432e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_model_1(texts):\n",
    "    return model_1_tokenizer(\n",
    "        texts, \n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenize training data\n",
    "train_encodings = tokenize_model_1(train_texts)\n",
    "train_input_ids = train_encodings['input_ids']\n",
    "train_attention_masks = train_encodings['attention_mask']\n",
    "train_labels = torch.tensor(train_labels)\n",
    "    \n",
    "# Tokenize test data\n",
    "test_encodings = tokenize_model_1(test_texts)\n",
    "test_input_ids = test_encodings['input_ids']\n",
    "test_attention_masks = test_encodings['attention_mask']\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb191ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21adeddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_dataset)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=test_sampler,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1329497f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__sizeof__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e82d78b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2762d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import bitsandbytes.optim as bnb_optim\n",
    "\n",
    "\n",
    "optimizer = bnb_optim.PagedAdamW8bit(model_1.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 1\n",
    "total_steps = len(train_dataloader) * epochs // GRADIENT_ACCUMULATION_STEPS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d25f083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4849df94af48fcac02efdc3bc6e951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Step 1/125 | Training loss: 7.5293\n",
      "\n",
      "  Step 2/125 | Training loss: 7.4759\n",
      "\n",
      "  Step 3/125 | Training loss: 7.4824\n",
      "\n",
      "  Step 4/125 | Training loss: 7.4637\n",
      "\n",
      "  Step 5/125 | Training loss: 7.3973\n",
      "\n",
      "  Step 6/125 | Training loss: 7.3623\n",
      "\n",
      "  Step 7/125 | Training loss: 7.2320\n",
      "\n",
      "  Step 8/125 | Training loss: 7.0608\n",
      "\n",
      "  Step 9/125 | Training loss: 6.9088\n",
      "\n",
      "  Step 10/125 | Training loss: 6.7390\n",
      "\n",
      "  Step 11/125 | Training loss: 6.5581\n",
      "\n",
      "  Step 12/125 | Training loss: 6.3675\n",
      "\n",
      "  Step 13/125 | Training loss: 6.1813\n",
      "\n",
      "  Step 14/125 | Training loss: 5.9827\n",
      "\n",
      "  Step 15/125 | Training loss: 5.7704\n",
      "\n",
      "  Step 16/125 | Training loss: 5.5616\n",
      "\n",
      "  Step 17/125 | Training loss: 5.3579\n",
      "\n",
      "  Step 18/125 | Training loss: 5.1764\n",
      "\n",
      "  Step 19/125 | Training loss: 5.0025\n",
      "\n",
      "  Step 20/125 | Training loss: 4.8678\n",
      "\n",
      "  Step 21/125 | Training loss: 4.7218\n",
      "\n",
      "  Step 22/125 | Training loss: 4.5852\n",
      "\n",
      "  Step 23/125 | Training loss: 4.4617\n",
      "\n",
      "  Step 24/125 | Training loss: 4.3489\n",
      "\n",
      "  Step 25/125 | Training loss: 4.2290\n",
      "\n",
      "  Step 26/125 | Training loss: 4.1449\n",
      "\n",
      "  Step 27/125 | Training loss: 4.0569\n",
      "\n",
      "  Step 28/125 | Training loss: 3.9932\n",
      "\n",
      "  Step 29/125 | Training loss: 3.9067\n",
      "\n",
      "  Step 30/125 | Training loss: 3.8450\n",
      "\n",
      "  Step 31/125 | Training loss: 3.7729\n",
      "\n",
      "  Step 32/125 | Training loss: 3.6972\n",
      "\n",
      "  Step 33/125 | Training loss: 3.6382\n",
      "\n",
      "  Step 34/125 | Training loss: 3.5960\n",
      "\n",
      "  Step 35/125 | Training loss: 3.5398\n",
      "\n",
      "  Step 36/125 | Training loss: 3.4929\n",
      "\n",
      "  Step 37/125 | Training loss: 3.4434\n",
      "\n",
      "  Step 38/125 | Training loss: 3.3966\n",
      "\n",
      "  Step 39/125 | Training loss: 3.3458\n",
      "\n",
      "  Step 40/125 | Training loss: 3.3036\n",
      "\n",
      "  Step 41/125 | Training loss: 3.2532\n",
      "\n",
      "  Step 42/125 | Training loss: 3.2123\n",
      "\n",
      "  Step 43/125 | Training loss: 3.1756\n",
      "\n",
      "  Step 44/125 | Training loss: 3.1383\n",
      "\n",
      "  Step 45/125 | Training loss: 3.1017\n",
      "\n",
      "  Step 46/125 | Training loss: 3.0737\n",
      "\n",
      "  Step 47/125 | Training loss: 3.0449\n",
      "\n",
      "  Step 48/125 | Training loss: 3.0151\n",
      "\n",
      "  Step 49/125 | Training loss: 2.9935\n",
      "\n",
      "  Step 50/125 | Training loss: 2.9676\n",
      "\n",
      "  Step 51/125 | Training loss: 2.9427\n",
      "\n",
      "  Step 52/125 | Training loss: 2.9232\n",
      "\n",
      "  Step 53/125 | Training loss: 2.9113\n",
      "\n",
      "  Step 54/125 | Training loss: 2.8950\n",
      "\n",
      "  Step 55/125 | Training loss: 2.8733\n",
      "\n",
      "  Step 56/125 | Training loss: 2.8562\n",
      "\n",
      "  Step 57/125 | Training loss: 2.8416\n",
      "\n",
      "  Step 58/125 | Training loss: 2.8172\n",
      "\n",
      "  Step 59/125 | Training loss: 2.8000\n",
      "\n",
      "  Step 60/125 | Training loss: 2.7861\n",
      "\n",
      "  Step 61/125 | Training loss: 2.7755\n",
      "\n",
      "  Step 62/125 | Training loss: 2.7548\n",
      "\n",
      "  Step 63/125 | Training loss: 2.7362\n",
      "\n",
      "  Step 64/125 | Training loss: 2.7125\n",
      "\n",
      "  Step 65/125 | Training loss: 2.6973\n",
      "\n",
      "  Step 66/125 | Training loss: 2.6770\n",
      "\n",
      "  Step 67/125 | Training loss: 2.6638\n",
      "\n",
      "  Step 68/125 | Training loss: 2.6426\n",
      "\n",
      "  Step 69/125 | Training loss: 2.6354\n",
      "\n",
      "  Step 70/125 | Training loss: 2.6203\n",
      "\n",
      "  Step 71/125 | Training loss: 2.6047\n",
      "\n",
      "  Step 72/125 | Training loss: 2.5908\n",
      "\n",
      "  Step 73/125 | Training loss: 2.5796\n",
      "\n",
      "  Step 74/125 | Training loss: 2.5749\n",
      "\n",
      "  Step 75/125 | Training loss: 2.5582\n",
      "\n",
      "  Step 76/125 | Training loss: 2.5580\n",
      "\n",
      "  Step 77/125 | Training loss: 2.5478\n",
      "\n",
      "  Step 78/125 | Training loss: 2.5360\n",
      "\n",
      "  Step 79/125 | Training loss: 2.5264\n",
      "\n",
      "  Step 80/125 | Training loss: 2.5166\n",
      "\n",
      "  Step 81/125 | Training loss: 2.5058\n",
      "\n",
      "  Step 82/125 | Training loss: 2.4952\n",
      "\n",
      "  Step 83/125 | Training loss: 2.4873\n",
      "\n",
      "  Step 84/125 | Training loss: 2.4818\n",
      "\n",
      "  Step 85/125 | Training loss: 2.4722\n",
      "\n",
      "  Step 86/125 | Training loss: 2.4668\n",
      "\n",
      "  Step 87/125 | Training loss: 2.4539\n",
      "\n",
      "  Step 88/125 | Training loss: 2.4486\n",
      "\n",
      "  Step 89/125 | Training loss: 2.4361\n",
      "\n",
      "  Step 90/125 | Training loss: 2.4313\n",
      "\n",
      "  Step 91/125 | Training loss: 2.4199\n",
      "\n",
      "  Step 92/125 | Training loss: 2.4143\n",
      "\n",
      "  Step 93/125 | Training loss: 2.4096\n",
      "\n",
      "  Step 94/125 | Training loss: 2.4020\n",
      "\n",
      "  Step 95/125 | Training loss: 2.3900\n",
      "\n",
      "  Step 96/125 | Training loss: 2.3781\n",
      "\n",
      "  Step 97/125 | Training loss: 2.3703\n",
      "\n",
      "  Step 98/125 | Training loss: 2.3712\n",
      "\n",
      "  Step 99/125 | Training loss: 2.3648\n",
      "\n",
      "  Step 100/125 | Training loss: 2.3573\n",
      "\n",
      "  Step 101/125 | Training loss: 2.3489\n",
      "\n",
      "  Step 102/125 | Training loss: 2.3440\n",
      "\n",
      "  Step 103/125 | Training loss: 2.3425\n",
      "\n",
      "  Step 104/125 | Training loss: 2.3340\n",
      "\n",
      "  Step 105/125 | Training loss: 2.3259\n",
      "\n",
      "  Step 106/125 | Training loss: 2.3223\n",
      "\n",
      "  Step 107/125 | Training loss: 2.3204\n",
      "\n",
      "  Step 108/125 | Training loss: 2.3145\n",
      "\n",
      "  Step 109/125 | Training loss: 2.3068\n",
      "\n",
      "  Step 110/125 | Training loss: 2.3024\n",
      "\n",
      "  Step 111/125 | Training loss: 2.2925\n",
      "\n",
      "  Step 112/125 | Training loss: 2.2853\n",
      "\n",
      "  Step 113/125 | Training loss: 2.2781\n",
      "\n",
      "  Step 114/125 | Training loss: 2.2696\n",
      "\n",
      "  Step 115/125 | Training loss: 2.2674\n",
      "\n",
      "  Step 116/125 | Training loss: 2.2614\n",
      "\n",
      "  Step 117/125 | Training loss: 2.2581\n",
      "\n",
      "  Step 118/125 | Training loss: 2.2570\n",
      "\n",
      "  Step 119/125 | Training loss: 2.2585\n",
      "\n",
      "  Step 120/125 | Training loss: 2.2548\n",
      "\n",
      "  Step 121/125 | Training loss: 2.2564\n",
      "\n",
      "  Step 122/125 | Training loss: 2.2476\n",
      "\n",
      "  Step 123/125 | Training loss: 2.2416\n",
      "\n",
      "  Step 124/125 | Training loss: 2.2386\n",
      "\n",
      "  Step 125/125 | Training loss: 2.2334\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "progress_bar = tqdm(range(total_steps))\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    print(f\"\\n======== Epoch {epoch_i + 1} / {epochs} ========\")\n",
    "    \n",
    "    model_1.train()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # We don't call `model_1.zero_grad()` here yet because we are accumulating.\n",
    "        \n",
    "        # The model calculates loss internally when `labels` are provided.\n",
    "        # The `labels` argument needs to be the same as `input_ids` for Causal LM loss.\n",
    "        outputs = model_1(\n",
    "            input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_input_ids # For a Causal LM, labels are typically the input_ids themselves\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # --- Gradient Accumulation Step ---\n",
    "        # Normalize the loss\n",
    "        loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        \n",
    "        # Backpropagate the normalized loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Accumulate loss for tracking\n",
    "        total_train_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "        \n",
    "        # --- Optimizer Step ---\n",
    "        # Only perform an optimizer step after accumulating for the specified number of steps.\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model_1.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad() # Reset gradients after the step\n",
    "            progress_bar.update(1)\n",
    "\n",
    "            avg_train_loss = total_train_loss / (step + 1)\n",
    "            print(f\"\\n  Step {progress_bar.n}/{total_steps} | Training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "816e13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save_pretrained(\"./qlora-finetuned-pythia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84413919",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "del model_1\n",
    "del model_1_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd225f0b",
   "metadata": {},
   "source": [
    "## Model 2 : StableLM (3B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5a86b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4c8f5c7e4541a2a8a6ef0b6c12a046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--stabilityai--stablelm-3b-4e1t. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb849973bb941c19bb1a798c4e53293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7cdac1e3124071a76be0101259bdc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2 = AutoModelForCausalLM.from_pretrained(\n",
    "    \"stabilityai/stablelm-3b-4e1t\",\n",
    "    quantization_config=qlora_config,\n",
    "    device_map=\"cuda\",\n",
    "    trust_remote_code=True,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7866ac04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StableLmForCausalLM(\n",
       "  (model): StableLmModel(\n",
       "    (embed_tokens): Embedding(50304, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x StableLmDecoderLayer(\n",
       "        (self_attn): StableLmSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (rotary_emb): StableLmRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): StableLmMLP(\n",
       "          (gate_proj): Linear4bit(in_features=2560, out_features=6912, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2560, out_features=6912, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=6912, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): StableLmRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa9d135c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe5e1ab04714d738af341ce90477f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/264 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcb1da22fe94867b2d537441b5d769c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891a74b257904cf9b2ea45c3967ed573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2_tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-3b-4e1t\")\n",
    "\n",
    "if model_2_tokenizer.pad_token is None:\n",
    "    model_2_tokenizer.pad_token = model_2_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3eee852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(model_2_tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f80d2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = model_2_tokenizer(test)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24e5b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12764, 2, 1359, 403, 368, 32]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text # test = \"Hi! How are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a715054",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.gradient_checkpointing_enable()\n",
    "model_2 = prepare_model_for_kbit_training(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a51fee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config_model_2 = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2acbecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = get_peft_model(model_2, lora_config_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1c4a935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 12,517,376 || all params: 2,807,960,576 || trainable%: 0.4458\n"
     ]
    }
   ],
   "source": [
    "model_2.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4434ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_model_2(texts):\n",
    "    return model_2_tokenizer(\n",
    "        texts, \n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenize training data\n",
    "train_encodings = tokenize_model_2(train_texts)\n",
    "train_input_ids = train_encodings['input_ids']\n",
    "train_attention_masks = train_encodings['attention_mask']\n",
    "train_labels = train_input_ids.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d22d6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels) \n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_dataset)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=test_sampler,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3162554e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14056167",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = bnb_optim.PagedAdamW8bit(model_2.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 1\n",
    "total_steps = len(train_dataloader) * epochs // GRADIENT_ACCUMULATION_STEPS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3235289f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26627025a3bb48efb7bc867bbae43564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Step 1/125 | Training loss: 5.4718\n",
      "\n",
      "  Step 2/125 | Training loss: 4.8463\n",
      "\n",
      "  Step 3/125 | Training loss: 4.3565\n",
      "\n",
      "  Step 4/125 | Training loss: 3.8744\n",
      "\n",
      "  Step 5/125 | Training loss: 3.4299\n",
      "\n",
      "  Step 6/125 | Training loss: 3.2003\n",
      "\n",
      "  Step 7/125 | Training loss: 2.8569\n",
      "\n",
      "  Step 8/125 | Training loss: 2.6543\n",
      "\n",
      "  Step 9/125 | Training loss: 2.4970\n",
      "\n",
      "  Step 10/125 | Training loss: 2.3785\n",
      "\n",
      "  Step 11/125 | Training loss: 2.2581\n",
      "\n",
      "  Step 12/125 | Training loss: 2.1530\n",
      "\n",
      "  Step 13/125 | Training loss: 2.1133\n",
      "\n",
      "  Step 14/125 | Training loss: 2.0667\n",
      "\n",
      "  Step 15/125 | Training loss: 2.0464\n",
      "\n",
      "  Step 16/125 | Training loss: 2.0216\n",
      "\n",
      "  Step 17/125 | Training loss: 2.0162\n",
      "\n",
      "  Step 18/125 | Training loss: 2.0143\n",
      "\n",
      "  Step 19/125 | Training loss: 1.9978\n",
      "\n",
      "  Step 20/125 | Training loss: 1.9963\n",
      "\n",
      "  Step 21/125 | Training loss: 1.9774\n",
      "\n",
      "  Step 22/125 | Training loss: 1.9747\n",
      "\n",
      "  Step 23/125 | Training loss: 1.9595\n",
      "\n",
      "  Step 24/125 | Training loss: 1.9529\n",
      "\n",
      "  Step 25/125 | Training loss: 1.9168\n",
      "\n",
      "  Step 26/125 | Training loss: 1.9002\n",
      "\n",
      "  Step 27/125 | Training loss: 1.8990\n",
      "\n",
      "  Step 28/125 | Training loss: 1.8685\n",
      "\n",
      "  Step 29/125 | Training loss: 1.8545\n",
      "\n",
      "  Step 30/125 | Training loss: 1.8432\n",
      "\n",
      "  Step 31/125 | Training loss: 1.8402\n",
      "\n",
      "  Step 32/125 | Training loss: 1.8261\n",
      "\n",
      "  Step 33/125 | Training loss: 1.8120\n",
      "\n",
      "  Step 34/125 | Training loss: 1.8115\n",
      "\n",
      "  Step 35/125 | Training loss: 1.8070\n",
      "\n",
      "  Step 36/125 | Training loss: 1.7900\n",
      "\n",
      "  Step 37/125 | Training loss: 1.7772\n",
      "\n",
      "  Step 38/125 | Training loss: 1.7836\n",
      "\n",
      "  Step 39/125 | Training loss: 1.7825\n",
      "\n",
      "  Step 40/125 | Training loss: 1.7729\n",
      "\n",
      "  Step 41/125 | Training loss: 1.7612\n",
      "\n",
      "  Step 42/125 | Training loss: 1.7570\n",
      "\n",
      "  Step 43/125 | Training loss: 1.7656\n",
      "\n",
      "  Step 44/125 | Training loss: 1.7463\n",
      "\n",
      "  Step 45/125 | Training loss: 1.7375\n",
      "\n",
      "  Step 46/125 | Training loss: 1.7384\n",
      "\n",
      "  Step 47/125 | Training loss: 1.7294\n",
      "\n",
      "  Step 48/125 | Training loss: 1.7340\n",
      "\n",
      "  Step 49/125 | Training loss: 1.7209\n",
      "\n",
      "  Step 50/125 | Training loss: 1.7171\n",
      "\n",
      "  Step 51/125 | Training loss: 1.7240\n",
      "\n",
      "  Step 52/125 | Training loss: 1.7147\n",
      "\n",
      "  Step 53/125 | Training loss: 1.7175\n",
      "\n",
      "  Step 54/125 | Training loss: 1.7133\n",
      "\n",
      "  Step 55/125 | Training loss: 1.7106\n",
      "\n",
      "  Step 56/125 | Training loss: 1.7024\n",
      "\n",
      "  Step 57/125 | Training loss: 1.6966\n",
      "\n",
      "  Step 58/125 | Training loss: 1.6965\n",
      "\n",
      "  Step 59/125 | Training loss: 1.6923\n",
      "\n",
      "  Step 60/125 | Training loss: 1.6913\n",
      "\n",
      "  Step 61/125 | Training loss: 1.6875\n",
      "\n",
      "  Step 62/125 | Training loss: 1.6856\n",
      "\n",
      "  Step 63/125 | Training loss: 1.6844\n",
      "\n",
      "  Step 64/125 | Training loss: 1.6876\n",
      "\n",
      "  Step 65/125 | Training loss: 1.6925\n",
      "\n",
      "  Step 66/125 | Training loss: 1.6874\n",
      "\n",
      "  Step 67/125 | Training loss: 1.6768\n",
      "\n",
      "  Step 68/125 | Training loss: 1.6731\n",
      "\n",
      "  Step 69/125 | Training loss: 1.6762\n",
      "\n",
      "  Step 70/125 | Training loss: 1.6715\n",
      "\n",
      "  Step 71/125 | Training loss: 1.6707\n",
      "\n",
      "  Step 72/125 | Training loss: 1.6685\n",
      "\n",
      "  Step 73/125 | Training loss: 1.6633\n",
      "\n",
      "  Step 74/125 | Training loss: 1.6651\n",
      "\n",
      "  Step 75/125 | Training loss: 1.6603\n",
      "\n",
      "  Step 76/125 | Training loss: 1.6653\n",
      "\n",
      "  Step 77/125 | Training loss: 1.6662\n",
      "\n",
      "  Step 78/125 | Training loss: 1.6618\n",
      "\n",
      "  Step 79/125 | Training loss: 1.6607\n",
      "\n",
      "  Step 80/125 | Training loss: 1.6601\n",
      "\n",
      "  Step 81/125 | Training loss: 1.6516\n",
      "\n",
      "  Step 82/125 | Training loss: 1.6526\n",
      "\n",
      "  Step 83/125 | Training loss: 1.6558\n",
      "\n",
      "  Step 84/125 | Training loss: 1.6542\n",
      "\n",
      "  Step 85/125 | Training loss: 1.6491\n",
      "\n",
      "  Step 86/125 | Training loss: 1.6506\n",
      "\n",
      "  Step 87/125 | Training loss: 1.6427\n",
      "\n",
      "  Step 88/125 | Training loss: 1.6372\n",
      "\n",
      "  Step 89/125 | Training loss: 1.6329\n",
      "\n",
      "  Step 90/125 | Training loss: 1.6292\n",
      "\n",
      "  Step 91/125 | Training loss: 1.6271\n",
      "\n",
      "  Step 92/125 | Training loss: 1.6275\n",
      "\n",
      "  Step 93/125 | Training loss: 1.6217\n",
      "\n",
      "  Step 94/125 | Training loss: 1.6178\n",
      "\n",
      "  Step 95/125 | Training loss: 1.6139\n",
      "\n",
      "  Step 96/125 | Training loss: 1.6131\n",
      "\n",
      "  Step 97/125 | Training loss: 1.6113\n",
      "\n",
      "  Step 98/125 | Training loss: 1.6077\n",
      "\n",
      "  Step 99/125 | Training loss: 1.6087\n",
      "\n",
      "  Step 100/125 | Training loss: 1.6022\n",
      "\n",
      "  Step 101/125 | Training loss: 1.6013\n",
      "\n",
      "  Step 102/125 | Training loss: 1.5979\n",
      "\n",
      "  Step 103/125 | Training loss: 1.5981\n",
      "\n",
      "  Step 104/125 | Training loss: 1.6011\n",
      "\n",
      "  Step 105/125 | Training loss: 1.6016\n",
      "\n",
      "  Step 106/125 | Training loss: 1.5961\n",
      "\n",
      "  Step 107/125 | Training loss: 1.5971\n",
      "\n",
      "  Step 108/125 | Training loss: 1.5947\n",
      "\n",
      "  Step 109/125 | Training loss: 1.5909\n",
      "\n",
      "  Step 110/125 | Training loss: 1.5938\n",
      "\n",
      "  Step 111/125 | Training loss: 1.5920\n",
      "\n",
      "  Step 112/125 | Training loss: 1.5915\n",
      "\n",
      "  Step 113/125 | Training loss: 1.5919\n",
      "\n",
      "  Step 114/125 | Training loss: 1.5884\n",
      "\n",
      "  Step 115/125 | Training loss: 1.5909\n",
      "\n",
      "  Step 116/125 | Training loss: 1.5950\n",
      "\n",
      "  Step 117/125 | Training loss: 1.5914\n",
      "\n",
      "  Step 118/125 | Training loss: 1.5901\n",
      "\n",
      "  Step 119/125 | Training loss: 1.5886\n",
      "\n",
      "  Step 120/125 | Training loss: 1.5906\n",
      "\n",
      "  Step 121/125 | Training loss: 1.5921\n",
      "\n",
      "  Step 122/125 | Training loss: 1.5903\n",
      "\n",
      "  Step 123/125 | Training loss: 1.5888\n",
      "\n",
      "  Step 124/125 | Training loss: 1.5923\n",
      "\n",
      "  Step 125/125 | Training loss: 1.5926\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(total_steps))\n",
    "model_2.train()\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    print(f\"\\n======== Epoch {epoch_i + 1} / {epochs} ========\")\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_2(\n",
    "            input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels \n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # --- Gradient Accumulation ---\n",
    "        loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        loss.backward()\n",
    "        \n",
    "        total_train_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "        \n",
    "        # --- Optimizer Step ---\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model_2.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "            avg_train_loss = total_train_loss / (step + 1)\n",
    "            print(f\"\\n  Step {progress_bar.n}/{total_steps} | Training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5dc85033",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save_pretrained(\"./qlora-finetuned-stableLM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
