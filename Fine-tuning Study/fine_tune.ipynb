{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72146d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def load_imdb_dataset():\n",
    "    imdb_dataset = load_dataset(\"imdb\")\n",
    "    N = 1000\n",
    "    rand_idx = np.random.randint(24999, size=N)\n",
    "    \n",
    "    x_train = imdb_dataset['train'][rand_idx]['text']\n",
    "    y_train = imdb_dataset['train'][rand_idx]['label']\n",
    "    \n",
    "    x_test = imdb_dataset['test'][rand_idx]['text']\n",
    "    y_test = imdb_dataset['test'][rand_idx]['label']\n",
    "    \n",
    "    return DatasetDict({'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n",
    "                        'test':Dataset.from_dict({'label':y_test,'text':x_test})})    \n",
    "\n",
    "dataset = load_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f5ca9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a48fd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.504)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b7064",
   "metadata": {},
   "source": [
    "## QLoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b79f7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.utils.quantization_config import BitsAndBytesConfig\n",
    "\n",
    "qlora_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44669e12",
   "metadata": {},
   "source": [
    "## Base Model : Pythia (2.8B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcde4bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e0372d2469426c8661c65b23cee2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--EleutherAI--pythia-2.8b. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e4aae711a24c2fb68bb13ee8b4fdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-2.8b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_1 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"EleutherAI/pythia-2.8b\",\n",
    "    num_labels = 2,\n",
    "    quantization_config = qlora_config,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c7b037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a87e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForSequenceClassification(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 2560)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (query_key_value): Linear4bit(in_features=2560, out_features=7680, bias=True)\n",
       "          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
       "          (dense_4h_to_h): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2560, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f0397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e30862f16a4ccabea2392150592ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e5043a2f7d42598b27881e67c76d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45f5666a4004380afb8d2ce2ef293c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_1_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-2.8b\")\n",
    "\n",
    "if model_1_tokenizer.pad_token is None:\n",
    "    model_1_tokenizer.pad_token = model_1_tokenizer.eos_token\n",
    "    model_1.config.pad_token_id = model_1.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a740545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(model_1_tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c3a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Hi! How are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bbec244",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = model_1_tokenizer(test)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5feba774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12764, 2, 1359, 403, 368, 32]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1ab20",
   "metadata": {},
   "source": [
    "## LoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "247b7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e38008b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig\n",
    "\n",
    "model_1 = prepare_model_for_kbit_training(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff117eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config_model_1 = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93033a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = get_peft_model(model_1, lora_config_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd8ab0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,490,880 || all params: 2,656,926,720 || trainable%: 0.3949\n"
     ]
    }
   ],
   "source": [
    "model_1.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ffb5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = dataset['train']['text']\n",
    "train_labels = dataset['train']['label']\n",
    "test_texts = dataset['test']['text']\n",
    "test_labels = dataset['test']['label']\n",
    "\n",
    "import re\n",
    "\n",
    "for i in range(len(train_texts)):\n",
    "    train_texts[i] = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", train_texts[i])\n",
    "    train_texts[i] = re.sub(r\"\\s+\", \" \", train_texts[i]).strip()\n",
    "for i in range(len(test_texts)):\n",
    "    test_texts[i] = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", test_texts[i])\n",
    "    test_texts[i] = re.sub(r\"\\s+\", \" \", test_texts[i]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed432e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_model_1(texts):\n",
    "    return model_1_tokenizer(\n",
    "        texts, \n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenize training data\n",
    "train_encodings = tokenize_model_1(train_texts)\n",
    "train_input_ids = train_encodings['input_ids']\n",
    "train_attention_masks = train_encodings['attention_mask']\n",
    "train_labels = torch.tensor(train_labels)\n",
    "    \n",
    "# Tokenize test data\n",
    "test_encodings = tokenize_model_1(test_texts)\n",
    "test_input_ids = test_encodings['input_ids']\n",
    "test_attention_masks = test_encodings['attention_mask']\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb191ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21adeddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_dataset)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=test_sampler,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1329497f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__sizeof__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e82d78b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2762d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import bitsandbytes.optim as bnb_optim\n",
    "\n",
    "\n",
    "optimizer = bnb_optim.PagedAdamW8bit(model_1.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 1\n",
    "total_steps = len(train_dataloader) * epochs // GRADIENT_ACCUMULATION_STEPS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d25f083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b6e026c64a4736ba3a046b76f41391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Step 1/125 | Training loss: 2.7787\n",
      "\n",
      "  Step 2/125 | Training loss: 1.9701\n",
      "\n",
      "  Step 3/125 | Training loss: 1.8852\n",
      "\n",
      "  Step 4/125 | Training loss: 1.8791\n",
      "\n",
      "  Step 5/125 | Training loss: 1.8648\n",
      "\n",
      "  Step 6/125 | Training loss: 1.7341\n",
      "\n",
      "  Step 7/125 | Training loss: 1.6727\n",
      "\n",
      "  Step 8/125 | Training loss: 1.5379\n",
      "\n",
      "  Step 9/125 | Training loss: 1.4705\n",
      "\n",
      "  Step 10/125 | Training loss: 1.3939\n",
      "\n",
      "  Step 11/125 | Training loss: 1.3483\n",
      "\n",
      "  Step 12/125 | Training loss: 1.3561\n",
      "\n",
      "  Step 13/125 | Training loss: 1.3730\n",
      "\n",
      "  Step 14/125 | Training loss: 1.3524\n",
      "\n",
      "  Step 15/125 | Training loss: 1.3287\n",
      "\n",
      "  Step 16/125 | Training loss: 1.3153\n",
      "\n",
      "  Step 17/125 | Training loss: 1.2912\n",
      "\n",
      "  Step 18/125 | Training loss: 1.3087\n",
      "\n",
      "  Step 19/125 | Training loss: 1.2616\n",
      "\n",
      "  Step 20/125 | Training loss: 1.2368\n",
      "\n",
      "  Step 21/125 | Training loss: 1.2483\n",
      "\n",
      "  Step 22/125 | Training loss: 1.2293\n",
      "\n",
      "  Step 23/125 | Training loss: 1.2024\n",
      "\n",
      "  Step 24/125 | Training loss: 1.1763\n",
      "\n",
      "  Step 25/125 | Training loss: 1.1741\n",
      "\n",
      "  Step 26/125 | Training loss: 1.1567\n",
      "\n",
      "  Step 27/125 | Training loss: 1.1671\n",
      "\n",
      "  Step 28/125 | Training loss: 1.1639\n",
      "\n",
      "  Step 29/125 | Training loss: 1.1500\n",
      "\n",
      "  Step 30/125 | Training loss: 1.1970\n",
      "\n",
      "  Step 31/125 | Training loss: 1.1783\n",
      "\n",
      "  Step 32/125 | Training loss: 1.1725\n",
      "\n",
      "  Step 33/125 | Training loss: 1.1778\n",
      "\n",
      "  Step 34/125 | Training loss: 1.1791\n",
      "\n",
      "  Step 35/125 | Training loss: 1.1644\n",
      "\n",
      "  Step 36/125 | Training loss: 1.1454\n",
      "\n",
      "  Step 37/125 | Training loss: 1.1355\n",
      "\n",
      "  Step 38/125 | Training loss: 1.1232\n",
      "\n",
      "  Step 39/125 | Training loss: 1.1106\n",
      "\n",
      "  Step 40/125 | Training loss: 1.0955\n",
      "\n",
      "  Step 41/125 | Training loss: 1.0864\n",
      "\n",
      "  Step 42/125 | Training loss: 1.0692\n",
      "\n",
      "  Step 43/125 | Training loss: 1.0716\n",
      "\n",
      "  Step 44/125 | Training loss: 1.0636\n",
      "\n",
      "  Step 45/125 | Training loss: 1.0559\n",
      "\n",
      "  Step 46/125 | Training loss: 1.0577\n",
      "\n",
      "  Step 47/125 | Training loss: 1.0519\n",
      "\n",
      "  Step 48/125 | Training loss: 1.0370\n",
      "\n",
      "  Step 49/125 | Training loss: 1.0312\n",
      "\n",
      "  Step 50/125 | Training loss: 1.0238\n",
      "\n",
      "  Step 51/125 | Training loss: 1.0305\n",
      "\n",
      "  Step 52/125 | Training loss: 1.0223\n",
      "\n",
      "  Step 53/125 | Training loss: 1.0322\n",
      "\n",
      "  Step 54/125 | Training loss: 1.0214\n",
      "\n",
      "  Step 55/125 | Training loss: 1.0123\n",
      "\n",
      "  Step 56/125 | Training loss: 1.0083\n",
      "\n",
      "  Step 57/125 | Training loss: 1.0038\n",
      "\n",
      "  Step 58/125 | Training loss: 0.9970\n",
      "\n",
      "  Step 59/125 | Training loss: 0.9963\n",
      "\n",
      "  Step 60/125 | Training loss: 0.9848\n",
      "\n",
      "  Step 61/125 | Training loss: 0.9808\n",
      "\n",
      "  Step 62/125 | Training loss: 0.9735\n",
      "\n",
      "  Step 63/125 | Training loss: 0.9724\n",
      "\n",
      "  Step 64/125 | Training loss: 0.9670\n",
      "\n",
      "  Step 65/125 | Training loss: 0.9570\n",
      "\n",
      "  Step 66/125 | Training loss: 0.9508\n",
      "\n",
      "  Step 67/125 | Training loss: 0.9463\n",
      "\n",
      "  Step 68/125 | Training loss: 0.9421\n",
      "\n",
      "  Step 69/125 | Training loss: 0.9374\n",
      "\n",
      "  Step 70/125 | Training loss: 0.9322\n",
      "\n",
      "  Step 71/125 | Training loss: 0.9299\n",
      "\n",
      "  Step 72/125 | Training loss: 0.9331\n",
      "\n",
      "  Step 73/125 | Training loss: 0.9243\n",
      "\n",
      "  Step 74/125 | Training loss: 0.9211\n",
      "\n",
      "  Step 75/125 | Training loss: 0.9206\n",
      "\n",
      "  Step 76/125 | Training loss: 0.9178\n",
      "\n",
      "  Step 77/125 | Training loss: 0.9190\n",
      "\n",
      "  Step 78/125 | Training loss: 0.9178\n",
      "\n",
      "  Step 79/125 | Training loss: 0.9153\n",
      "\n",
      "  Step 80/125 | Training loss: 0.9119\n",
      "\n",
      "  Step 81/125 | Training loss: 0.9089\n",
      "\n",
      "  Step 82/125 | Training loss: 0.9027\n",
      "\n",
      "  Step 83/125 | Training loss: 0.8975\n",
      "\n",
      "  Step 84/125 | Training loss: 0.8927\n",
      "\n",
      "  Step 85/125 | Training loss: 0.8958\n",
      "\n",
      "  Step 86/125 | Training loss: 0.8923\n",
      "\n",
      "  Step 87/125 | Training loss: 0.8869\n",
      "\n",
      "  Step 88/125 | Training loss: 0.8833\n",
      "\n",
      "  Step 89/125 | Training loss: 0.8766\n",
      "\n",
      "  Step 90/125 | Training loss: 0.8720\n",
      "\n",
      "  Step 91/125 | Training loss: 0.8692\n",
      "\n",
      "  Step 92/125 | Training loss: 0.8700\n",
      "\n",
      "  Step 93/125 | Training loss: 0.8647\n",
      "\n",
      "  Step 94/125 | Training loss: 0.8598\n",
      "\n",
      "  Step 95/125 | Training loss: 0.8576\n",
      "\n",
      "  Step 96/125 | Training loss: 0.8570\n",
      "\n",
      "  Step 97/125 | Training loss: 0.8528\n",
      "\n",
      "  Step 98/125 | Training loss: 0.8561\n",
      "\n",
      "  Step 99/125 | Training loss: 0.8517\n",
      "\n",
      "  Step 100/125 | Training loss: 0.8448\n",
      "\n",
      "  Step 101/125 | Training loss: 0.8390\n",
      "\n",
      "  Step 102/125 | Training loss: 0.8340\n",
      "\n",
      "  Step 103/125 | Training loss: 0.8369\n",
      "\n",
      "  Step 104/125 | Training loss: 0.8326\n",
      "\n",
      "  Step 105/125 | Training loss: 0.8309\n",
      "\n",
      "  Step 106/125 | Training loss: 0.8267\n",
      "\n",
      "  Step 107/125 | Training loss: 0.8201\n",
      "\n",
      "  Step 108/125 | Training loss: 0.8170\n",
      "\n",
      "  Step 109/125 | Training loss: 0.8124\n",
      "\n",
      "  Step 110/125 | Training loss: 0.8078\n",
      "\n",
      "  Step 111/125 | Training loss: 0.8071\n",
      "\n",
      "  Step 112/125 | Training loss: 0.8060\n",
      "\n",
      "  Step 113/125 | Training loss: 0.8092\n",
      "\n",
      "  Step 114/125 | Training loss: 0.8045\n",
      "\n",
      "  Step 115/125 | Training loss: 0.8009\n",
      "\n",
      "  Step 116/125 | Training loss: 0.7954\n",
      "\n",
      "  Step 117/125 | Training loss: 0.7908\n",
      "\n",
      "  Step 118/125 | Training loss: 0.7883\n",
      "\n",
      "  Step 119/125 | Training loss: 0.7859\n",
      "\n",
      "  Step 120/125 | Training loss: 0.7846\n",
      "\n",
      "  Step 121/125 | Training loss: 0.7832\n",
      "\n",
      "  Step 122/125 | Training loss: 0.7789\n",
      "\n",
      "  Step 123/125 | Training loss: 0.7807\n",
      "\n",
      "  Step 124/125 | Training loss: 0.7803\n",
      "\n",
      "  Step 125/125 | Training loss: 0.7770\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "progress_bar = tqdm(range(total_steps))\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    print(f\"\\n======== Epoch {epoch_i + 1} / {epochs} ========\")\n",
    "    \n",
    "    model_1.train()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # We don't call `model_1.zero_grad()` here yet because we are accumulating.\n",
    "        \n",
    "        # The model calculates loss internally when `labels` are provided.\n",
    "        outputs = model_1(\n",
    "            input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # --- Gradient Accumulation Step ---\n",
    "        # Normalize the loss\n",
    "        loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        \n",
    "        # Backpropagate the normalized loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Accumulate loss for tracking\n",
    "        total_train_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "        \n",
    "        # --- Optimizer Step ---\n",
    "        # Only perform an optimizer step after accumulating for the specified number of steps.\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model_1.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad() # Reset gradients after the step\n",
    "            progress_bar.update(1)\n",
    "\n",
    "            avg_train_loss = total_train_loss / (step + 1)\n",
    "            print(f\"\\n  Step {progress_bar.n}/{total_steps} | Training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "816e13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save_pretrained(\"./qlora-finetuned-pythia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84413919",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd225f0b",
   "metadata": {},
   "source": [
    "## Model 2 : StableLM (3B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5a86b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827dee6ab56e4b0b9c406edd128e8ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--stabilityai--stablelm-3b-4e1t. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be3939bc94f4dce83dfa5e78060e8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of StableLmForSequenceClassification were not initialized from the model checkpoint at stabilityai/stablelm-3b-4e1t and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"stabilityai/stablelm-3b-4e1t\",\n",
    "    quantization_config=qlora_config,\n",
    "    trust_remote_code=True,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7866ac04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StableLmForSequenceClassification(\n",
       "  (model): StableLmModel(\n",
       "    (embed_tokens): Embedding(50304, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x StableLmDecoderLayer(\n",
       "        (self_attn): StableLmSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (rotary_emb): StableLmRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): StableLmMLP(\n",
       "          (gate_proj): Linear4bit(in_features=2560, out_features=6912, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2560, out_features=6912, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=6912, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): StableLmRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2560, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa9d135c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3b3235dbab4d6d8079613059103cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/264 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0215a9798d546378ab55465267e32a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254e583b04e14b549a8969e4db35cc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2_tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-3b-4e1t\")\n",
    "\n",
    "if model_2_tokenizer.pad_token is None:\n",
    "    model_2_tokenizer.pad_token = model_2_tokenizer.eos_token\n",
    "    model_2.config.pad_token_id = model_2.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3eee852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(model_2_tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f80d2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = model_2_tokenizer(test)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24e5b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12764, 2, 1359, 403, 368, 32]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text # test = \"Hi! How are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a715054",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.gradient_checkpointing_enable()\n",
    "model_2 = prepare_model_for_kbit_training(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a51fee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config_model_2 = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2acbecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = get_peft_model(model_2, lora_config_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1c4a935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 12,522,496 || all params: 2,679,192,576 || trainable%: 0.4674\n"
     ]
    }
   ],
   "source": [
    "model_2.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4434ee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20188\\1742152744.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20188\\1742152744.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_labels = torch.tensor(test_labels)\n"
     ]
    }
   ],
   "source": [
    "def tokenize_model_2(texts):\n",
    "    return model_2_tokenizer(\n",
    "        texts, \n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenize training data\n",
    "train_encodings = tokenize_model_2(train_texts)\n",
    "train_input_ids = train_encodings['input_ids']\n",
    "train_attention_masks = train_encodings['attention_mask']\n",
    "train_labels = torch.tensor(train_labels)\n",
    "    \n",
    "# Tokenize test data\n",
    "test_encodings = tokenize_model_2(test_texts)\n",
    "test_input_ids = test_encodings['input_ids']\n",
    "test_attention_masks = test_encodings['attention_mask']\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d22d6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels) \n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_dataset)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=test_sampler,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3162554e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14056167",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = bnb_optim.PagedAdamW8bit(model_2.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 1\n",
    "total_steps = len(train_dataloader) * epochs // GRADIENT_ACCUMULATION_STEPS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3235289f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2768bbdbb675401ea5f7a50acbd2fd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "\n",
      "  Step 1/125 | Training loss: 6.4083\n",
      "\n",
      "  Step 2/125 | Training loss: 3.7711\n",
      "\n",
      "  Step 3/125 | Training loss: 3.3151\n",
      "\n",
      "  Step 4/125 | Training loss: 2.9306\n",
      "\n",
      "  Step 5/125 | Training loss: 2.5893\n",
      "\n",
      "  Step 6/125 | Training loss: 2.4233\n",
      "\n",
      "  Step 7/125 | Training loss: 2.1239\n",
      "\n",
      "  Step 8/125 | Training loss: 1.9037\n",
      "\n",
      "  Step 9/125 | Training loss: 1.8333\n",
      "\n",
      "  Step 10/125 | Training loss: 1.6766\n",
      "\n",
      "  Step 11/125 | Training loss: 1.5871\n",
      "\n",
      "  Step 12/125 | Training loss: 1.4966\n",
      "\n",
      "  Step 13/125 | Training loss: 1.4737\n",
      "\n",
      "  Step 14/125 | Training loss: 1.4333\n",
      "\n",
      "  Step 15/125 | Training loss: 1.4193\n",
      "\n",
      "  Step 16/125 | Training loss: 1.4255\n",
      "\n",
      "  Step 17/125 | Training loss: 1.3750\n",
      "\n",
      "  Step 18/125 | Training loss: 1.3255\n",
      "\n",
      "  Step 19/125 | Training loss: 1.3321\n",
      "\n",
      "  Step 20/125 | Training loss: 1.3274\n",
      "\n",
      "  Step 21/125 | Training loss: 1.3384\n",
      "\n",
      "  Step 22/125 | Training loss: 1.3585\n",
      "\n",
      "  Step 23/125 | Training loss: 1.3158\n",
      "\n",
      "  Step 24/125 | Training loss: 1.2830\n",
      "\n",
      "  Step 25/125 | Training loss: 1.2520\n",
      "\n",
      "  Step 26/125 | Training loss: 1.2236\n",
      "\n",
      "  Step 27/125 | Training loss: 1.2294\n",
      "\n",
      "  Step 28/125 | Training loss: 1.2172\n",
      "\n",
      "  Step 29/125 | Training loss: 1.2035\n",
      "\n",
      "  Step 30/125 | Training loss: 1.1922\n",
      "\n",
      "  Step 31/125 | Training loss: 1.1924\n",
      "\n",
      "  Step 32/125 | Training loss: 1.1803\n",
      "\n",
      "  Step 33/125 | Training loss: 1.1587\n",
      "\n",
      "  Step 34/125 | Training loss: 1.1520\n",
      "\n",
      "  Step 35/125 | Training loss: 1.1492\n",
      "\n",
      "  Step 36/125 | Training loss: 1.1182\n",
      "\n",
      "  Step 37/125 | Training loss: 1.1023\n",
      "\n",
      "  Step 38/125 | Training loss: 1.0788\n",
      "\n",
      "  Step 39/125 | Training loss: 1.0788\n",
      "\n",
      "  Step 40/125 | Training loss: 1.0580\n",
      "\n",
      "  Step 41/125 | Training loss: 1.0331\n",
      "\n",
      "  Step 42/125 | Training loss: 1.0306\n",
      "\n",
      "  Step 43/125 | Training loss: 1.0106\n",
      "\n",
      "  Step 44/125 | Training loss: 0.9992\n",
      "\n",
      "  Step 45/125 | Training loss: 0.9801\n",
      "\n",
      "  Step 46/125 | Training loss: 0.9608\n",
      "\n",
      "  Step 47/125 | Training loss: 0.9420\n",
      "\n",
      "  Step 48/125 | Training loss: 0.9241\n",
      "\n",
      "  Step 49/125 | Training loss: 0.9086\n",
      "\n",
      "  Step 50/125 | Training loss: 0.8983\n",
      "\n",
      "  Step 51/125 | Training loss: 0.8825\n",
      "\n",
      "  Step 52/125 | Training loss: 0.8657\n",
      "\n",
      "  Step 53/125 | Training loss: 0.8536\n",
      "\n",
      "  Step 54/125 | Training loss: 0.8437\n",
      "\n",
      "  Step 55/125 | Training loss: 0.8349\n",
      "\n",
      "  Step 56/125 | Training loss: 0.8244\n",
      "\n",
      "  Step 57/125 | Training loss: 0.8101\n",
      "\n",
      "  Step 58/125 | Training loss: 0.8093\n",
      "\n",
      "  Step 59/125 | Training loss: 0.7968\n",
      "\n",
      "  Step 60/125 | Training loss: 0.7985\n",
      "\n",
      "  Step 61/125 | Training loss: 0.7866\n",
      "\n",
      "  Step 62/125 | Training loss: 0.7897\n",
      "\n",
      "  Step 63/125 | Training loss: 0.7867\n",
      "\n",
      "  Step 64/125 | Training loss: 0.7767\n",
      "\n",
      "  Step 65/125 | Training loss: 0.7658\n",
      "\n",
      "  Step 66/125 | Training loss: 0.7679\n",
      "\n",
      "  Step 67/125 | Training loss: 0.7666\n",
      "\n",
      "  Step 68/125 | Training loss: 0.7695\n",
      "\n",
      "  Step 69/125 | Training loss: 0.7585\n",
      "\n",
      "  Step 70/125 | Training loss: 0.7540\n",
      "\n",
      "  Step 71/125 | Training loss: 0.7434\n",
      "\n",
      "  Step 72/125 | Training loss: 0.7342\n",
      "\n",
      "  Step 73/125 | Training loss: 0.7246\n",
      "\n",
      "  Step 74/125 | Training loss: 0.7360\n",
      "\n",
      "  Step 75/125 | Training loss: 0.7262\n",
      "\n",
      "  Step 76/125 | Training loss: 0.7287\n",
      "\n",
      "  Step 77/125 | Training loss: 0.7193\n",
      "\n",
      "  Step 78/125 | Training loss: 0.7101\n",
      "\n",
      "  Step 79/125 | Training loss: 0.7011\n",
      "\n",
      "  Step 80/125 | Training loss: 0.6924\n",
      "\n",
      "  Step 81/125 | Training loss: 0.6933\n",
      "\n",
      "  Step 82/125 | Training loss: 0.6849\n",
      "\n",
      "  Step 83/125 | Training loss: 0.6773\n",
      "\n",
      "  Step 84/125 | Training loss: 0.6721\n",
      "\n",
      "  Step 85/125 | Training loss: 0.6700\n",
      "\n",
      "  Step 86/125 | Training loss: 0.6660\n",
      "\n",
      "  Step 87/125 | Training loss: 0.6592\n",
      "\n",
      "  Step 88/125 | Training loss: 0.6517\n",
      "\n",
      "  Step 89/125 | Training loss: 0.6445\n",
      "\n",
      "  Step 90/125 | Training loss: 0.6373\n",
      "\n",
      "  Step 91/125 | Training loss: 0.6412\n",
      "\n",
      "  Step 92/125 | Training loss: 0.6454\n",
      "\n",
      "  Step 93/125 | Training loss: 0.6446\n",
      "\n",
      "  Step 94/125 | Training loss: 0.6443\n",
      "\n",
      "  Step 95/125 | Training loss: 0.6454\n",
      "\n",
      "  Step 96/125 | Training loss: 0.6386\n",
      "\n",
      "  Step 97/125 | Training loss: 0.6378\n",
      "\n",
      "  Step 98/125 | Training loss: 0.6320\n",
      "\n",
      "  Step 99/125 | Training loss: 0.6257\n",
      "\n",
      "  Step 100/125 | Training loss: 0.6194\n",
      "\n",
      "  Step 101/125 | Training loss: 0.6171\n",
      "\n",
      "  Step 102/125 | Training loss: 0.6120\n",
      "\n",
      "  Step 103/125 | Training loss: 0.6094\n",
      "\n",
      "  Step 104/125 | Training loss: 0.6036\n",
      "\n",
      "  Step 105/125 | Training loss: 0.5978\n",
      "\n",
      "  Step 106/125 | Training loss: 0.5995\n",
      "\n",
      "  Step 107/125 | Training loss: 0.5975\n",
      "\n",
      "  Step 108/125 | Training loss: 0.5926\n",
      "\n",
      "  Step 109/125 | Training loss: 0.5872\n",
      "\n",
      "  Step 110/125 | Training loss: 0.5820\n",
      "\n",
      "  Step 111/125 | Training loss: 0.5768\n",
      "\n",
      "  Step 112/125 | Training loss: 0.5877\n",
      "\n",
      "  Step 113/125 | Training loss: 0.5825\n",
      "\n",
      "  Step 114/125 | Training loss: 0.5784\n",
      "\n",
      "  Step 115/125 | Training loss: 0.5733\n",
      "\n",
      "  Step 116/125 | Training loss: 0.5733\n",
      "\n",
      "  Step 117/125 | Training loss: 0.5708\n",
      "\n",
      "  Step 118/125 | Training loss: 0.5660\n",
      "\n",
      "  Step 119/125 | Training loss: 0.5713\n",
      "\n",
      "  Step 120/125 | Training loss: 0.5673\n",
      "\n",
      "  Step 121/125 | Training loss: 0.5627\n",
      "\n",
      "  Step 122/125 | Training loss: 0.5581\n",
      "\n",
      "  Step 123/125 | Training loss: 0.5557\n",
      "\n",
      "  Step 124/125 | Training loss: 0.5537\n",
      "\n",
      "  Step 125/125 | Training loss: 0.5657\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(total_steps))\n",
    "model_2.train()\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    print(f\"\\n======== Epoch {epoch_i + 1} / {epochs} ========\")\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_2(\n",
    "            input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels \n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # --- Gradient Accumulation ---\n",
    "        loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        loss.backward()\n",
    "        \n",
    "        total_train_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "        \n",
    "        # --- Optimizer Step ---\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model_2.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "            avg_train_loss = total_train_loss / (step + 1)\n",
    "            print(f\"\\n  Step {progress_bar.n}/{total_steps} | Training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5dc85033",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save_pretrained(\"./qlora-finetuned-stableLM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
