{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72146d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def load_imdb_dataset():\n",
    "    imdb_dataset = load_dataset(\"imdb\")\n",
    "    N = 1000\n",
    "    rand_idx = np.random.randint(24999, size=N)\n",
    "    \n",
    "    x_train = imdb_dataset['train'][rand_idx]['text']\n",
    "    y_train = imdb_dataset['train'][rand_idx]['label']\n",
    "    \n",
    "    x_test = imdb_dataset['test'][rand_idx]['text']\n",
    "    y_test = imdb_dataset['test'][rand_idx]['label']\n",
    "    \n",
    "    return DatasetDict({'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n",
    "                        'test':Dataset.from_dict({'label':y_test,'text':x_test})})    \n",
    "\n",
    "dataset = load_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f5ca9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a48fd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.504)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b7064",
   "metadata": {},
   "source": [
    "## QLoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b79f7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.utils.quantization_config import BitsAndBytesConfig\n",
    "\n",
    "qlora_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44669e12",
   "metadata": {},
   "source": [
    "## Model : TinyLlama-1.1B-Chatv1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_1 = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    num_labels = 2,\n",
    "    quantization_config = qlora_config,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7b037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a87e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_1_tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "if model_1_tokenizer.pad_token is None:\n",
    "    model_1_tokenizer.pad_token = model_1_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a740545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n"
     ]
    }
   ],
   "source": [
    "print(model_1_tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c3a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Hi! How are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bbec244",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = model_1_tokenizer(test)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5feba774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6324, 29991, 1128, 526, 366, 29973]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1ab20",
   "metadata": {},
   "source": [
    "## LoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "247b7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e38008b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig\n",
    "\n",
    "model_1 = prepare_model_for_kbit_training(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff117eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93033a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = get_peft_model(model_1, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd8ab0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,307,840 || all params: 1,106,356,224 || trainable%: 0.5701\n"
     ]
    }
   ],
   "source": [
    "model_1.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ffb5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = dataset['train']['text']\n",
    "train_labels = dataset['train']['label']\n",
    "test_texts = dataset['test']['text']\n",
    "test_labels = dataset['test']['label']\n",
    "\n",
    "import re\n",
    "\n",
    "for i in range(len(train_texts)):\n",
    "    train_texts[i] = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", train_texts[i])\n",
    "    train_texts[i] = re.sub(r\"\\s+\", \" \", train_texts[i]).strip()\n",
    "for i in range(len(test_texts)):\n",
    "    test_texts[i] = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", test_texts[i])\n",
    "    test_texts[i] = re.sub(r\"\\s+\", \" \", test_texts[i]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed432e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts):\n",
    "    return model_1_tokenizer(\n",
    "        texts, \n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenize training data\n",
    "train_encodings = tokenize(train_texts)\n",
    "train_input_ids = train_encodings['input_ids']\n",
    "train_attention_masks = train_encodings['attention_mask']\n",
    "train_labels = torch.tensor(train_labels)\n",
    "    \n",
    "# Tokenize test data\n",
    "test_encodings = tokenize(test_texts)\n",
    "test_input_ids = test_encodings['input_ids']\n",
    "test_attention_masks = test_encodings['attention_mask']\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21adeddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_dataset)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=test_sampler,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e82d78b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2762d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import bitsandbytes.optim as bnb_optim\n",
    "\n",
    "\n",
    "optimizer = bnb_optim.PagedAdamW8bit(model_1.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 1\n",
    "total_steps = len(train_dataloader) * epochs // GRADIENT_ACCUMULATION_STEPS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d25f083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536b087f6269402f9e98750929979869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Step 1/125 | Training loss: 6.7019\n",
      "\n",
      "  Step 2/125 | Training loss: 6.5796\n",
      "\n",
      "  Step 3/125 | Training loss: 6.1343\n",
      "\n",
      "  Step 4/125 | Training loss: 5.8453\n",
      "\n",
      "  Step 5/125 | Training loss: 5.4075\n",
      "\n",
      "  Step 6/125 | Training loss: 5.0608\n",
      "\n",
      "  Step 7/125 | Training loss: 4.6996\n",
      "\n",
      "  Step 8/125 | Training loss: 4.3935\n",
      "\n",
      "  Step 9/125 | Training loss: 4.1953\n",
      "\n",
      "  Step 10/125 | Training loss: 4.0272\n",
      "\n",
      "  Step 11/125 | Training loss: 3.8350\n",
      "\n",
      "  Step 12/125 | Training loss: 3.6478\n",
      "\n",
      "  Step 13/125 | Training loss: 3.4740\n",
      "\n",
      "  Step 14/125 | Training loss: 3.3412\n",
      "\n",
      "  Step 15/125 | Training loss: 3.2929\n",
      "\n",
      "  Step 16/125 | Training loss: 3.1967\n",
      "\n",
      "  Step 17/125 | Training loss: 3.1356\n",
      "\n",
      "  Step 18/125 | Training loss: 3.0441\n",
      "\n",
      "  Step 19/125 | Training loss: 2.9901\n",
      "\n",
      "  Step 20/125 | Training loss: 2.9497\n",
      "\n",
      "  Step 21/125 | Training loss: 2.8749\n",
      "\n",
      "  Step 22/125 | Training loss: 2.8294\n",
      "\n",
      "  Step 23/125 | Training loss: 2.7675\n",
      "\n",
      "  Step 24/125 | Training loss: 2.7085\n",
      "\n",
      "  Step 25/125 | Training loss: 2.6503\n",
      "\n",
      "  Step 26/125 | Training loss: 2.6296\n",
      "\n",
      "  Step 27/125 | Training loss: 2.6091\n",
      "\n",
      "  Step 28/125 | Training loss: 2.5787\n",
      "\n",
      "  Step 29/125 | Training loss: 2.5447\n",
      "\n",
      "  Step 30/125 | Training loss: 2.5128\n",
      "\n",
      "  Step 31/125 | Training loss: 2.5218\n",
      "\n",
      "  Step 32/125 | Training loss: 2.4951\n",
      "\n",
      "  Step 33/125 | Training loss: 2.4653\n",
      "\n",
      "  Step 34/125 | Training loss: 2.4623\n",
      "\n",
      "  Step 35/125 | Training loss: 2.4565\n",
      "\n",
      "  Step 36/125 | Training loss: 2.4420\n",
      "\n",
      "  Step 37/125 | Training loss: 2.4199\n",
      "\n",
      "  Step 38/125 | Training loss: 2.4002\n",
      "\n",
      "  Step 39/125 | Training loss: 2.3873\n",
      "\n",
      "  Step 40/125 | Training loss: 2.3698\n",
      "\n",
      "  Step 41/125 | Training loss: 2.3386\n",
      "\n",
      "  Step 42/125 | Training loss: 2.3292\n",
      "\n",
      "  Step 43/125 | Training loss: 2.3116\n",
      "\n",
      "  Step 44/125 | Training loss: 2.2969\n",
      "\n",
      "  Step 45/125 | Training loss: 2.2917\n",
      "\n",
      "  Step 46/125 | Training loss: 2.2765\n",
      "\n",
      "  Step 47/125 | Training loss: 2.2711\n",
      "\n",
      "  Step 48/125 | Training loss: 2.2550\n",
      "\n",
      "  Step 49/125 | Training loss: 2.2334\n",
      "\n",
      "  Step 50/125 | Training loss: 2.2155\n",
      "\n",
      "  Step 51/125 | Training loss: 2.2103\n",
      "\n",
      "  Step 52/125 | Training loss: 2.1895\n",
      "\n",
      "  Step 53/125 | Training loss: 2.1814\n",
      "\n",
      "  Step 54/125 | Training loss: 2.1657\n",
      "\n",
      "  Step 55/125 | Training loss: 2.1519\n",
      "\n",
      "  Step 56/125 | Training loss: 2.1370\n",
      "\n",
      "  Step 57/125 | Training loss: 2.1266\n",
      "\n",
      "  Step 58/125 | Training loss: 2.1187\n",
      "\n",
      "  Step 59/125 | Training loss: 2.1148\n",
      "\n",
      "  Step 60/125 | Training loss: 2.1020\n",
      "\n",
      "  Step 61/125 | Training loss: 2.0939\n",
      "\n",
      "  Step 62/125 | Training loss: 2.0833\n",
      "\n",
      "  Step 63/125 | Training loss: 2.0760\n",
      "\n",
      "  Step 64/125 | Training loss: 2.0661\n",
      "\n",
      "  Step 65/125 | Training loss: 2.0583\n",
      "\n",
      "  Step 66/125 | Training loss: 2.0458\n",
      "\n",
      "  Step 67/125 | Training loss: 2.0433\n",
      "\n",
      "  Step 68/125 | Training loss: 2.0406\n",
      "\n",
      "  Step 69/125 | Training loss: 2.0286\n",
      "\n",
      "  Step 70/125 | Training loss: 2.0204\n",
      "\n",
      "  Step 71/125 | Training loss: 2.0179\n",
      "\n",
      "  Step 72/125 | Training loss: 2.0182\n",
      "\n",
      "  Step 73/125 | Training loss: 2.0075\n",
      "\n",
      "  Step 74/125 | Training loss: 2.0071\n",
      "\n",
      "  Step 75/125 | Training loss: 1.9981\n",
      "\n",
      "  Step 76/125 | Training loss: 2.0015\n",
      "\n",
      "  Step 77/125 | Training loss: 2.0025\n",
      "\n",
      "  Step 78/125 | Training loss: 1.9933\n",
      "\n",
      "  Step 79/125 | Training loss: 1.9888\n",
      "\n",
      "  Step 80/125 | Training loss: 1.9864\n",
      "\n",
      "  Step 81/125 | Training loss: 1.9853\n",
      "\n",
      "  Step 82/125 | Training loss: 1.9838\n",
      "\n",
      "  Step 83/125 | Training loss: 1.9755\n",
      "\n",
      "  Step 84/125 | Training loss: 1.9696\n",
      "\n",
      "  Step 85/125 | Training loss: 1.9636\n",
      "\n",
      "  Step 86/125 | Training loss: 1.9688\n",
      "\n",
      "  Step 87/125 | Training loss: 1.9662\n",
      "\n",
      "  Step 88/125 | Training loss: 1.9634\n",
      "\n",
      "  Step 89/125 | Training loss: 1.9553\n",
      "\n",
      "  Step 90/125 | Training loss: 1.9498\n",
      "\n",
      "  Step 91/125 | Training loss: 1.9473\n",
      "\n",
      "  Step 92/125 | Training loss: 1.9470\n",
      "\n",
      "  Step 93/125 | Training loss: 1.9480\n",
      "\n",
      "  Step 94/125 | Training loss: 1.9448\n",
      "\n",
      "  Step 95/125 | Training loss: 1.9448\n",
      "\n",
      "  Step 96/125 | Training loss: 1.9370\n",
      "\n",
      "  Step 97/125 | Training loss: 1.9324\n",
      "\n",
      "  Step 98/125 | Training loss: 1.9279\n",
      "\n",
      "  Step 99/125 | Training loss: 1.9239\n",
      "\n",
      "  Step 100/125 | Training loss: 1.9164\n",
      "\n",
      "  Step 101/125 | Training loss: 1.9129\n",
      "\n",
      "  Step 102/125 | Training loss: 1.9152\n",
      "\n",
      "  Step 103/125 | Training loss: 1.9154\n",
      "\n",
      "  Step 104/125 | Training loss: 1.9120\n",
      "\n",
      "  Step 105/125 | Training loss: 1.9031\n",
      "\n",
      "  Step 106/125 | Training loss: 1.8974\n",
      "\n",
      "  Step 107/125 | Training loss: 1.8927\n",
      "\n",
      "  Step 108/125 | Training loss: 1.8951\n",
      "\n",
      "  Step 109/125 | Training loss: 1.8939\n",
      "\n",
      "  Step 110/125 | Training loss: 1.8917\n",
      "\n",
      "  Step 111/125 | Training loss: 1.8932\n",
      "\n",
      "  Step 112/125 | Training loss: 1.8964\n",
      "\n",
      "  Step 113/125 | Training loss: 1.8954\n",
      "\n",
      "  Step 114/125 | Training loss: 1.8944\n",
      "\n",
      "  Step 115/125 | Training loss: 1.8966\n",
      "\n",
      "  Step 116/125 | Training loss: 1.8930\n",
      "\n",
      "  Step 117/125 | Training loss: 1.8885\n",
      "\n",
      "  Step 118/125 | Training loss: 1.8865\n",
      "\n",
      "  Step 119/125 | Training loss: 1.8849\n",
      "\n",
      "  Step 120/125 | Training loss: 1.8798\n",
      "\n",
      "  Step 121/125 | Training loss: 1.8823\n",
      "\n",
      "  Step 122/125 | Training loss: 1.8807\n",
      "\n",
      "  Step 123/125 | Training loss: 1.8814\n",
      "\n",
      "  Step 124/125 | Training loss: 1.8783\n",
      "\n",
      "  Step 125/125 | Training loss: 1.8761\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "progress_bar = tqdm(range(total_steps))\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    print(f\"\\n======== Epoch {epoch_i + 1} / {epochs} ========\")\n",
    "    \n",
    "    model_1.train()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # We don't call `model_1.zero_grad()` here yet because we are accumulating.\n",
    "        \n",
    "        # The model calculates loss internally when `labels` are provided.\n",
    "        # The `labels` argument needs to be the same as `input_ids` for Causal LM loss.\n",
    "        outputs = model_1(\n",
    "            input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_input_ids # For a Causal LM, labels are typically the input_ids themselves\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # --- Gradient Accumulation Step ---\n",
    "        # Normalize the loss\n",
    "        loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "        \n",
    "        # Backpropagate the normalized loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Accumulate loss for tracking\n",
    "        total_train_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "        \n",
    "        # --- Optimizer Step ---\n",
    "        # Only perform an optimizer step after accumulating for the specified number of steps.\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model_1.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad() # Reset gradients after the step\n",
    "            progress_bar.update(1)\n",
    "\n",
    "            avg_train_loss = total_train_loss / (step + 1)\n",
    "            print(f\"\\n  Step {progress_bar.n}/{total_steps} | Training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "816e13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save_pretrained(\"./qlora-finetuned-imdb-final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
